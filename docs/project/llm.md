# LLM-интеграция

## Провайдеры

Поддерживаются два провайдера (паттерн «Стратегия»):

- **OpenRouter** (`OpenRouterStrategy`).
- **Cliproxy** (`CliproxyStrategy`) — локальный или кастомный прокси с OpenAI-совместимым API.

Выбор провайдера выполняется в `Header`.

## Настройки подключения

Данные хранятся в `localStorage`:

- `openRouterKey` — API ключ OpenRouter.
- `openRouterEndpoint` — базовый URL OpenRouter.
- `proxyEndpoint` — URL локального прокси.
- `proxyKey` — ключ прокси (если требуется).

## Получение моделей

- **OpenRouter**: `GET {endpoint}/v1/models` (требуется ключ).
- **Cliproxy**: последовательная проверка `/v1/models`, `/models`, `/api/models`.

В UI доступны фильтры моделей: free-only и context ≥ 8k.

## Системные промпты

Промпты формируются централизованно в `services/llm/prompts.ts`:

- Поддерживаются режимы: `generate`, `fix`, `chat`, `analyze`.
- Поддерживаются языки: RU/EN (auto → EN).
- В промпт передается тип диаграммы и контекст документации.
- Контекст обрезается по лимитам (см. `DOC_LIMITS`).

## Авто-определение языка

Если в UI выбран `Auto`, язык определяется по последнему пользовательскому сообщению и записывается в состояние приложения.

## Контекст документации

`docsContextService` загружает локальные Markdown-файлы Mermaid-документации
из `diagram-compiler/public/mermaid-docs` и добавляет их в системный промпт.

## Контекст текущей диаграммы

При наличии текущего Mermaid-кода он добавляется в контекст LLM как отдельное сообщение, чтобы модель могла учитывать текущую диаграмму при Chat/Build.

## Поведение режимов

- **Chat** — текстовый ответ без Mermaid-кода.
- **Build** — генерация Mermaid-кода, затем валидация и авто-фикс при необходимости.
- **Fix** — исправление Mermaid-синтаксиса по сообщению ошибки.
- **Analyze** — объяснение диаграммы без генерации кода.
